## 1. Fetch抓取
- (1) Hive中对某些情况的查询可以不必使用MapReduce计算，如select * from test;这种情况下，Hive可简单地读取test对应的存储目录下的文件，然后输出给控制台。
- (2) hive.fetch.task.conversion默认为more，表示全局查找、字段查找、limit查找都不需要走mapreduce，可以参考hive-default.xml.template中的解释
```shell
# 设置为none，表示均需要执行mapreduce任务
hive> set hive.fetch.task.conversion=none;
hive> select * from test;
hive> select name from test;
hive> select name from test limit 3;
# 设置为more，select, filter, limit相关语句不会执行mapreduce
hive> select * from test;
hive> select name from test;
hive> select name from test limit 3;
```


## 2. 本地模式
- (1) 大多数HadoopJob需要hadoop提供完整的可扩展性来处理大数据集。不过，有时hive的输入数据量非常小。此时，为查询触发执行任务消耗的时间可能会比实际job执行时间更长。对于这种情况，Hive可以通过本地模式在单台机器上处理所有的任务。对于小数据集，执行时间可以明显缩短
- (2) 可通过设置hive.exec.model.local.auto为true，让hive在适当时候自动启动该优化
```shell
hive> set hive.exec.mode.local.auto=true;
hive> select count(*) from log_text; # 执行时间为3.82s
```

## 3. 表的优化
- (1) 小表和大表join：高版本已进行优化，小表和大表的位置不影响
```shell
# 测试大表join小表和小表join大表的效率
hive> create table if not exists smalltable(id bigint, timing bigint, uid string, keyword string, url_rank int,
    > click_num int, click_url string) row format delimited fields terminated by '\t';
hive> create table if not exists bigtable(id bigint, timing bigint, uid string, keyword string, url_rank int,
    > click_num int, click_url string) row format delimited fields terminated by '\t';
hive> create table if not exists jointable(id bigint, timing bigint, uid string, keyword string, url_rank int,
    > click_num int, click_url string) row format delimited fields terminated by '\t';
# 分别向大表和小表导入数据
hive> load data local inpath '/home/ws/module/hive/data/smalltable' into table smalltable;
hive> load data local inpath '/home/ws/module/hive/data/bigtable' into table bigtable;
# 执行小表join大表，执行时长：172.572 s
hive> insert overwrite table jointable
    > select b.id, b.timing, b.uid, b.keyword, b.url_rank, b.click_num, b.click_url
    > from smalltable s
    > left join bigtable b
    > on b.id = s.id;
# 执行大表join小表，执行时长：185.124 s
hive> insert overwrite table jointable
    > select b.id, b.timing, b.uid, b.keyword, b.url_rank, b.click_num, b.click_url
    > from bigtable b
    > left join smalltable s
    > on s.id = b.id;
```

- (2) 大表join大表
- 1) 空key过滤
有时join超时是因为某些key对应的数据太多，相同key对应的数据都会发送到相同的reducer上，从而导致内存不够。此时我们应该仔细分析这些异常的key，很多情况下，这些key对应的数据是异常数据，需要在SQL语句中进行过滤。
```shell
示例：
# 创建原始数据表、空id表、合并后数据表
hive> create table if not exists ori(id bigint, timing bigint, uid string, keyword string, url_rank int, click_num int, click_url string) row format delimited fields terminated by '\t';
hive> create table if not exists nullidtable(id bigint, timing bigint, uid string, keyword string, url_rank int, click_num int, click_url string) row format delimited fields terminated by '\t';
hive> create table if not exists jointable(id bigint, timing bigint, uid string, keyword string, url_rank int, click_num int, click_url string) row format delimited fields terminated by '\t';
# 加载数据
hive> load data local inpath '/home/xxguan2/module/hive/data/ori' into table ori;
hive> load data local inpath '/home/xxguan2/module/hive/data/nullid' into table nullidtable;
# 不过滤空id，执行时长54 s
hive> insert overwrite table jointable select n.* from nullidtable n left join ori o on n.id=o.id;
# 过滤空id，执行时长44 s
hive> insert overwrite table jointable select n.* from (select * from nullidtable where id is not null) n left join ori o on n.id=o.id;
```

- 2) 空key转换
有时虽然某个key为空对应的数据很多，但相应的数据不是异常数据，必须要包含在join的结果中。此时可以在表a中key为空的字段赋一个随机值，使得数据随机均匀地分到不同的reducer上。
```shell
# 设置reduce的个数
hive> set mapreduce.job.reduces=5;
# JOIN，可以看到每个reduce由于数据倾斜导致执行时间不相同
hive> insert overwrite table jointable select n.* from nullidtable n left join ori o on n.id=o.id;
# 随机分布null值，可以看到数据倾斜的情况减少
hive> insert overwrite table jointable select n.* from nullidtable n full join ori o on case when n.id is null then concat('hive', rand()) else n.id end = o.id;
```

- (3) MapJoin
若不指定MapJoin或不符合MapJoin条件，Hive会将Join操作转换为common join，即在reduce阶段完成join。容易发生数据倾斜。可以用MapJoin把小表全部加载到内存在map端进行join，避免reduce处理。
```shell
# 开启MapJoin参数设置
hive> set hive.auto.convert.join=true;
# 大表小表的阈值设置(默认25M)
hive> set hive.mapjoin.smalltable.filesize=25000000;
```

- (4) Group By
- a. 默认情况下，Map阶段同一key数据分发给同一个reduce，当一个key数据过大时就倾斜。并不是所有的聚合操作都需要再reduce端完成，很多聚合操作都可以先在Map端进行部分聚合，最后在reduce端得出最终结果。
- b. 当hive.groupby.skewindata为true时，生成的查询计划会有两个MR job。第一个MR Job中，Map的输出结果会随机分布到reduce中，每个reduce做部分聚合操作，并输出结果。这样的处理结果是相同的group by key有可能被分发到不同的reduce中，从而达到负载均衡的目的。第二个MR Job再根据预处理的数据结果按照group by key分布到reduce中(可以保证相同的group by key被分布到同一个reduce中)，最后完成最终的聚合操作。
```shell
# 开启Map端聚合参数设置(默认为true)
hive> set hive.map.aggr=true;
# 在Map端进行聚合操作的条目数目
hive> set hive.groupby.mapaggr.checkinterval=100000;
# 有数据倾斜的时候进行负载均衡(默认false)
hive> set hive.groupby.skewindata=true;
```

- (5) count(distinct)去重统计
数据量小的时候无所谓，数据量大的情况下，由于count distinct操作需要用一个reduce task来完成，这一个reduce需要处理的数据量太大，会导致整个job很难完成，一般count distinct使用先group by再count的方式替换。
```shell
# 设置reduce的个数
hive> set mapreduce.job.reduces=5;
# 执行id去重，会存在一个map和一个reduce
hive> select count(distinct id) from bigtable;
# 采用group by 去重id，会存在2个job，第一个job存在一个mao和5个reduce，第二个job会存在一个map和一个reduce。
# 在数据量大的情况推荐采用这种方案，可以减少数据倾斜
hive> select count(id) from (select id from bigtable group by id) a;
```

- (6) 笛卡尔积：尽量避免笛卡尔积，join的时候不加on条件，或者无效的on条件，Hive只能使用1个reducer来完成笛卡尔积。
```shell
hive> select e.ename, d.dname from emp e, dept d;
```

- (7) 行列过滤
- a. 列处理：在select中，只拿需要的列，如果有，尽量使用分区过滤，少用select *
- b. 行处理：在分区裁剪中， 当使用外关联时，如果将副表的过滤条件写在where后面，name就会先全表关联，之后再过滤
```shell
# 先关联两张表，再用where条件过滤，执行时间34.7s
hive> select o.id from bigtable b join ori o on o.id=b.id where o.id<=10;
# 通过子查询，再关联表, 执行时间35.4
hive> select b.id from bigtable b join (select id from ori where id <= 10) o on b.id = o.id;
```

- (8) 动态分区
关系型数据库中，对分区表insert数据时，数据库自动会根据分区字段的值，将数据插入到相应的分区中，Hive中也提供了类似的机制即动态分区(Dynamic Partition)。
```shell
a. 开启动态分区参数设置
# 开启动态分区功能(默认为true)
hive> set hive.exec.dynamic.partition;
# 设置非严格模式(动态分区的模式，默认strict，表示必须指定一个分区为静态分区，nonstrict模式表示允许所有的分区字段都可以使用动态分区)
hive> set hive.exec.dynamic.partition.mode=nonstrict;
# 在所有执行MR的节点上，最大可以创建多少个动态分区。
hive> set hive.exec.max.dynamic.partitions=1000;
# 在每个执行MR的节点上，最大可以创建多少个动态分区。# 该参数需要根据实际的数据来设定。比如，源数据中包含一年的数据，即day字段有365个值，那么该参数就需要设置成大于365，如果使用默认100，就会报错
hive> set hive.exec.max.dynamic.partitions.pernode=100;
# 整个MR job中，最大可以创建多少个HDFS文件
hive> set hive.exec.max.created.files=100000;
# 当有空分区生成时，是否抛出异常，一般不需要配置
hive> set hive.error.on.empty.partition=false;
b. 示例
# 创建分区表：
hive> create table ori_partitioned(id bigint, timing bigint, uid string, keyword string, url_rank int, click_num int, click_url string) partitioned by (p_time bigint) row format delimited fields terminated by '\t';
# 导入数据到指定分区
hive> load data local inpath '/home/ws/module/hive/data/smalltable' into table ori_partitioned partition(p_time='001');
hive> load data local inpath '/home/ws/module/hive/data/smalltable' into table ori_partitioned partition(p_time='002');
hive> load data local inpath '/home/ws/module/hive/data/smalltable' into table ori_partitioned partition(p_time='003');
# 创建目标分区表
hive> create table ori_partitioned_target(id bigint, timing bigint, uid string, keyword string, url_rank int, click_num int, click_url string) partitioned by (p_time bigint) row format delimited fields terminated by '\t';
#
hive> insert overwrite table ori_partitioned_target partition (p_time) select id, timing, uid, keyword, url_rank, click_num, click_url, p_time from ori_partitioned;
```