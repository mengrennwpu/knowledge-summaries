## 1 从外部导入到Hive表
### 1.1 创建表stu，且默认以"\t"进行分割
```shell
    hive> create table stu(id int, name string) row format delimited fields terminated by '\t';
```

### 1.2 从本地加载数据到hive指定表
```shell
hive> load data local inpath '/path/file' into table table_name;
```
```
    注意：
    a. /path/file中属性之间以"\t"分割
    b. 本地load相当于文件的复制
```

### 1.3 从HDFS加载数据到hive指定表
```shell
    hive> load data inpath '/path/file' into table table_name;
```
```
    注意：
    a. /path/file中属性之间以"\t"分割
    b. 与本地的区别在于：无local
    c. HDFS文件load相当于移动，即HDFS中的/path/file将会执行move
```

### 1.4 可以通过将文件put到指定的hive所在表路径中也可以实现数据加载到hive表
- 从HDFS中加载到hive指定表，本质上是是将文件上传或移动到HDFS中的hive所在的表中，因此直接上传同样格式的文件，放在hive对应的表目录中，然后在hive命令行中直接查询，也可以查询到新的数据。
```shell
    例：
    $ hadoop fs -put student1.txt /tmp # 上传文件，文件内容为1\tws\n2\tly
    hive> load data inpath '/tmp/student1.txt' into table stu;
    hive> select * from stu;
    $ hadoop fs -cat /user/hive/warehouse/stu/student1.txt # 显示结果为1\tws\n2\tly
    $ hadoop fs -put student2.txt /user/hive/warehouse/stu # 上传新文件到HDFS中的Hive目录下的stu表中，内容为：7\ttest\n8\tsb
    hive> select * from stu; # student2.txt中的内容可以正常显示
```

### 1.5 外部资源操作
- (1) 增加文件、jar包、文档等：add file[s]/jar[s]/archive[s] <filepath> <filepath> *
- (2) 查看添加的文件、jar包、文档等：list file[s]/jar[s]/archive[s] [<filepath> <filepath> *]
- (3) 删除田间的文件、jar包、文档等：delete file[s]/jar[s]/archive[s] <filepath> <filepath> *


## 2. derby数据库
- 默认单一用户登录，因此同时打开多个hive客户端就会报错。目前常见的解决方案是用mysql作为hive存储元数据的数据库。
- 如何安装，可以参考：https://www.cnblogs.com/mengrennwpu/p/11892306.html
- 可以关注mysql中的DBS,TLBS,PARTION等相关的表信息。


##3. hiveserver2和beeline
- (1) 如果需要第三方连接Hive时，需要开启hiveserver2服务及beeline。以下为二者的简单使用：
- a. hadoop的core-site.xml需要增加如下配置，其中ws为连接用户
```java
        <property>
            <name>hadoop.proxyuser.ws.hosts</name>
            <value>*</value>
        </property>
        <property>
            <name>hadoop.proxyuser.ws.groups</name>
            <value>*</value>
        </property>
```
- b. 启动hiveserver2: ./bin/hiveserver2
- c. 启动beeline：beeline -u jdbc:hive2://localhost:10000 -n ws，即可执行相关命令
- d. 退出beeline: !quit
- (2) 启动beeline可以增加诸多参数
- 1) --outputformat，表示结果展示的格式
- a. table: 默认为table
- b. vertical: 以key-value进行列式显示
- c. xmlattr: 以xml格式展示，且每一列中存在"result"元素
- d. xmlelements: 以xml格式展示，"result"为元素，属性和值作为result的子属性
- e. csv: 引号包裹属性，逗号作为属性分隔符
- f. csv2: 相比csv少了引号
- g. tsv: 与csv的区别在于以tab作为分隔符
- h. tsv2: 与tsv相比少了引号
- i. dsv: 默认以'|'作为分隔符，可通过beeline --delimiterForDSV进行配置
- (3) hiveserver2中的JDBC
- 可参考![HiveServer2 Clients](https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=82903124#HiveServer2Clients-Separated-ValueOutputFormats)


## 4. 运行hive
- 并不是只能通过hive cli才能进行hive操作，也可以通过如下方式
- 1) 直接执行hive -e 'sql'：hive -e 'select * from aa'
- 2) 将SQL写入文件file，然后执行hive -f file > result
```shell
> hive --hiveconf hive.root.logger=INFO,console # 设置hive客户端的日志级别 
```
- 3) 变量替换：结合set具有灵活的操作性
```shell script
$ hive --hiveconf a=b -e 'set a; set hiveconf:a; create table if not exists b (col int); describe ${hiveconf:a};'
# 结果如下:
Hive Session ID = f8fc94e7-69b2-4299-94a3-0aba9626cc9f
a=b
hiveconf:a=b
OK
Time taken: 3.002 seconds
OK
col_name	data_type	comment
col                 	int                 	                    
Time taken: 0.198 seconds, Fetched: 1 row(s)

# 其他示例：
set zzz=5;
--  sets zzz=5
set zzz;
 
set system:xxx=5;
set system:xxx;
-- sets a system property xxx to 5
 
set system:yyy=${system:xxx};
set system:yyy;
-- sets yyy with value of xxx
 
set go=${hiveconf:zzz};
set go;
-- sets go base on value on zzz
 
set hive.variable.substitute=false;
set raw=${hiveconf:zzz};
set raw;
-- disable substitution set a value to the literal
 
set hive.variable.substitute=true;
 
EXPLAIN SELECT * FROM src where key=${hiveconf:zzz};
SELECT * FROM src where key=${hiveconf:zzz};
--use a variable in a query
 
set a=1;
set b=a;
set c=${hiveconf:${hiveconf:b}};
set c;
--uses nested variables.
 
 
set jar=../lib/derby.jar;
 
add file ${hiveconf:jar};
list file;
delete file ${hiveconf:jar};
list file;
```

## 5. 其他操作
```shell
    a. hive> dfs ls /; # hive cli窗口中查看hdfs
    b. hive> ! ls /home; # hive cli中查看本地目录
    c. cat ~/.hivehistory # 查看当前用户在hive中输入的所有命令
```


## 6 参数配置方式
- a. 通过配置文件：hive-site.xml(用户自定义配置文件)，hive-default.xml(默认配置文件)，且前者优先级高于后者
- b. 命令行参数方式配置，但只限本次有效：hive -hiveconf param=value设置，如：hive -hiveconf mapred.reduce.tasks=10;
- c. hive cli中通过set param=value设置：
```shell
    hive> set mapred-reduce.tasks=20 # 进行设置
    hive> set mapred-reduce.tasks # 查看设置
```