## 1. 基本查询
### 1.1 查询格式
```
SELECT [ALL | DISTINCT] select_expr, select_expr,... FORM table_reference
    [WHERE where_condition]
    [GROUP BY col_list]
    [ORDER BY col_list]
    [CLUSTER BY col_list | [DISTRIBUTE BY col_list] [SORT BY col_list]]
    [LIMIT number]
```

### 1.2 列别名
可以重命名一个列，便于计算，其格式为紧跟列名，也可以在列名和别名之间加入关键字'AS'  
```
hive> select name as person_name, id unicodeId from test;
```

### 1.3 算术运算符
- A+B, A-B, A*B, A/B, A%B  
- A&B, A|B, A^B, ~A：按位进行运算  
```
hive> select id + 1 as unicodeId from test;
```

### 1.5 逻辑运算符
- A and B 等同于 A && B
- A or B 等同于 A || B
- not A 等同于 !A


### 1.4 常用函数
- 求总行数  
```hive> select count(*) as cnt from test;```
- 求指定列去重后的值  
```hive> select count(distinct foo, bar) from invites;```
- 求最大值  
```hive> select max(id) max_id from test;```
- 求最小值  
```hive> select min(id) max_id from test;```
- 求总和  
```hive> select sum(id) sum_id from test;```
- 求指定列去重后的总和
```hive> select sum(distinct id) sum_id from test;```
- 求平均值  
```hive> select avg(id) avg_id from test;```
- 求指定列去重后的平均值
```hive> select avg(distinct id) avg_id from test;```
- limit  
```hive> select * from test limit 2;```
- get_json_object：获取json中的对象  
```hive> select get_json_object('{"store":{"fruit":[{"weight":8,"type":"apple"}, {"weight":9,"type":"pear"}]}, "email":"123@qq.com","owner":"any"}','$.store.fruit[1].weight');```
- round(double a): 返回四舍五入后的BIGINT值
- floor(double a):返回<=a的最大BIGINT值
- ceil(double a)： 返回>=a的最小BIGINT值
- rand(), rand(seed): 返回随机值
- substring(string a, int start): 返回子串，注意索引从1开始
- substring(string a, int start, int length): 返回子串
```shell
hive> select substr('foobar', 4);	# bar
hive> select substr('foobar', 4, 2);	# ba

```
- upper(string a)等同于ucase(string a): 转换为大写
- lower(string a)等同于lcase(string a): 转换为小写
- trim(string a), ltrim(string a), rtrim(string a)
- regexp_replace(string a, string b, string c): a为原始字串，b为正则，c为预替换的值
```shell
hive>select regexp_replace('hello world', '[\\s]+', '|');	# hello|world
```
- size(Map<k,v>), size(Array<T>): 返回array和map的大小
- from_unixtime(int unixtime): 时间戳转化为时间
- to_date(string time): 返回日期部分
- year(string date): 返回年份
- month(string date): 返回月份
- day(string date): 返回日期
```shell
hive> select from_unixtime(0);
hive> select from_unixtime(0, 'yyyy');
hive> select to_date('2020-06-23 12:00');
hive> select year('2020-06-23');
hive> select month('2020-06-23');
hive> select day('2020-06-23');
```

## 2. Where语句
### 2.1 查询id为1的数据
```hive> select * from test where id=1;```

### 2.2 比较运算符
- a. A=B:     A=B则为true，否则为false
- b. A<=B>:   若A和B均为NULL，则返true，其他情况与=操作符结果一致；若A和B任一个为NULL，则结果为NULL
- c. A<>B:    A或B为NULL，则返回NULL
- d. A!=B:    A不等于B，返回为true，否则为false
- e. A<B:     A或B为NULL，则返回NULL；如果A小于B，则返回true，否则为false
- f. A<=B:    A或B为NULL，则返回NULL；如果A小于等于B，则返回true，否则为false
- g. A>B:     A或B为NULL，则返回NULL；如果A大于B，则返回true，否则为false
- h. A>=B:    A或B为NULL，则返回NULL；如果A大于等于B，则返回true，否则为false
- i. A [NOT] BETWEEN B AND C: A,B,C任一为NULL，则结果为NULL，如果A大于B且小于等于C，则为true，否则为false。使用NOT可以得到相反的结果
- j. A IS [NOT] NULL: A为NULL，返回true，否则为false。使用NOT可以得到相反的结果
- k. IN (number, number2): IN运算显示列表中的值
- l. A [NOT] like B: B是SQL的简单表达式，如果A与其匹配，返回true，否则为false。  B表达式："x%"表示A必须以字母'x'开头;"%x"表示A必须以字母'x'结尾
- k. A RLIKE B, A REGEXP B: B为正则表达式  
```shell
示例：  
# 查询薪水等于5000的所有员工：  
hive> select * from emp where sal=5000;  
# 查询工资在500到1000的员工：  
hive> select * from emp where sal between 500 and 1000;  
# 查询comm为空的员工信息  
hive> select * from emp where comm is null;  
# 查询工资是1000或5000的员工  
hive> select * from emp where sal IN (1000, 5000);  
```

### 2.3 like、rlike、regexp
- a. 选择条件可以包含字符或数字: %代表零个或多个任意字符，_代表一个字符
- b. RLike是Hive功能扩展，可以通过Java正则表达式指定匹配条件
- c. regexp与rlike功能一致
```shell
示例：
    # 查找以2开头的薪水的员工信息
    hive> select * from emp where sal like '2%';
    # 查找第二个数值为2的薪水的员工信息
    hive> select * from emp where sal like '_2%';
    # 查找薪水中包含2的员工信息
    hive> select * from emp where sal rlike '[2]';
    4) 逻辑运算符：AND, OR, NOT
    # 查询薪水大于1000，部门是30
    hive> select * from emp where sal>1000 and deptno=30;
    # 查询薪水大于1000，或者部门使30
    hive> select * from emp where sal>1000 or deptno=30;
    # 查询除了20和30部门以外的员工信息
    hive> select * from emp where deptno not IN (20, 30);
```

## 3. 分组
### 3.1 group by
通常会和聚合函数一起使用，按照一个或多个列结果进行分组，然后对每个组进行聚合操作
```shell
    # 计算emp表每个部门的平均工资
    hive> select t.deptno, avg(t.sal) avg_sal from emp t group by t.deptno;
    # 计算emp表每个部门中每个岗位的最高薪水
    hive> select t.deotno, t.job, max(t.sal) max_sal from emp t group by t.deptno, t.job;
```

### 3.2 Having语句：
- a. where针对表中的列发挥作用，查询数据；having针对查询结果的列发挥作用，筛选数据
- b. where后面不能写分组函数，而having可以使用分组函数
- c. having只用于group by分组统计语句
```shell
示例：
    # 求每个部门的平均工资
    hive> select deptno, avg(sal) from emp group by deptno;
    # 求每个部门的平均薪水大于2000的部门
    hive> select deptno, avg(sal) avg_sal from emp group by deptno having avg_sal > 2000;
```


## 4. Join语句
### 4.1 等值Join
Hive支持通常SQL JOIN语句，但只支持等值连接，不支持非等值连接
```shell
    示例：
    # 根据员工表和部门表中的部门编号相等，查询员工编号、员工名称和部门名称
    hive> select e.empno, e.ename, d.deptno, d.dname from emp e join dept d on e.deptno=d.deptno;
```

### 4.2 内连接
只有进行连接的两个表中都存在与该连接条件相匹配的数据才会被保留下来
```shell
    hive> select e.empno, e.ename, d.deptno from emp e join dept d on e.deptno = d.deptno;
```

### 4.3 左外连接
JOIN操作符左边表中符合where子句的所有记录都将被返回
```shell
    hive> select e.empno, e.ename, d.deptno from emp e left join dept d on e.deptno=d.deptno;
```

### 4.4 右外连接
JOIN操作符右边表中符合where子句的所有记录都将被返回
```shell
    hive> select e.empno, e.ename, d.deptno from emp e right join dept d on e.deptno=d.deptno;
```

### 4.5 满外连接
将会返回所有表中符合where语句条件的所有记录。如果任一表的指定字段没有符合条件的值得话，那么使用NULL替代
```shell
    hive> select e.empno, e.ename, d.deptno from emp e full join dept d on e.deptno=d.deptno;
```

### 4.6 多表连接：连接n个表，至少需要n-1个连接条件
```注意：大多数情况下，Hive会对每对JOIN连接对象启动一个Mapreduce任务```
```shell
    hive> create table if not exists default.location(loc int, loc_name string)
        > row format delimited fields terminated by '\t';
    hive> load data local inpath '/home/test/module/hive/data/location.txt' into table default.location;
    hive> select e.ename, d.deptno, l.loc_name from emp e
        > join dept d on d.deptno=e.deptno # 先启动一个MR对e和d进行连接操作
        > join location l on d.loc = l.loc;  # 再启动一个MR将第一个MR的输出和表l进行连接操作。
```
    
### 4.7 笛卡尔积
```注意：生产环境禁止使用```
- a. 产生条件: join时省略连接条件; 连接条件无效; 所有表中的所有行互相连接
```shell
    示例：
    hive> select empno, dname from emp, dept;
```

### 4.8 join谓词不支持or
```shell
    示例：
    hive> select e.empno, e.ename, d.deptno from emp e join dept d on e.deptno=d.deptno or e.ename=d.ename; # 异常
```


## 5. 排序
### 5.1 全局排序: Order by
- a. 只会生成一个reduce
- b. order by用于select语句之后
```shell
    示例：
    # 查询员工信息按工资升序排序
    hive> select * from emp order by sal;
    # 查询员工信息按工资降序排序
    hive> select * from emp order by sal desc;
```

### 5.2 按照别名排序
```shell
    # 按照员工薪水的2倍排序
    hive> select ename, sal*2 2sal from emp order by 2sal;
```

### 5.3 多个列排序
```shell
    # 按照部门和工资升序排列
    hive> select ename, deptno, sal from emp order by deptno, sal;
```

### 5.4 每个MR内部排序
- Sort by => 每个reduce内部进行排序，对全局结果集来说不是排序，且随机分区，防止数据倾斜
```shell
    hive> set mapreduce.job.reduces=3;  # 设置reduce的个数
    hive> set mapreduce.job.reduces;    # 查看reduce个数
    # 根据部门编号降序查看员工信息
    hive> select * from emp sort by empno desc;
    # 将排序结果导入到文件中(按照部门编号降序排序)
    hive> insert overwrite local directory '/home/test/module/hive/data/sort_result'
        > select * from emp sort by deptno desc;
```

### 5.5 分区排序
- distribute by, 类似于MR中的partition进行分区，结合sort by使用，并写在sort by之前。
- 注意：
- a. distribute by的分区规则是根据分区字段hash码与reduce的个数进行模除后，余数相同的分到一个区
- b. hive要求distribute by要写在sort by之前
```shell
    hive> set mapreduce.job.reduces=3;
    # 先按照部门编号分区，再按照员工编号降序排序
    hive> insert overwrite local directory '/home/test/module/hive/data/distribute_result'
        > select * from emp distribute by deptno sort by empno desc; # 输出3个文件，每个文件中deptno的相同，且sal降序排序
```

### 5.6 cluster by
- 当distribute by 和sort by字段相同时，可以使用cluster by方式。
```注意：cluster by排序时只能是倒序排序，不能指定排序规则为ASC或者DESC```
```shell
    # 以下两种方法等价
    hive> select * from emp cluster by deptno;
    hive> select * from emp distribute by deptno sort by deptno;
```

## 6. 分桶及抽样查询
### 6.1 分桶表数据存储
- 针对于大数据量的数据文件
- a. 分区针对的是数据的存储路径，分桶针对的是数据文件
- b. 分区提供一个隔离数据和优化查询的便利方式，但是，并不是所有的数据集都可形成合理的分区；分桶是将数据集分解成更容易管理的若干部分的另一个技术
```shell
    # 创建分桶表
    hive> create table student_bucket(id int, name string)
        > clustered by (id) into 4 buckets
        > row format delimited fields terminated by '\t';
    # 加载数据
    hive> load data local inpath '/home/test/module/hive/data/student.txt'
        > into table student_bucket;
    # 查看HDFS中的数据，可以看到文件被分为4份，且每个数据大小为4
    hive> dfs -ls /user/hive/warehouse/hive/student_bucket;
```

### 6.2 分桶抽样查询
- a. 对于非常大的数据集，有时用户需要使用的是一个具有代表性的查询结果而非全部结果，Hive可以通过对表进行抽样来满足这个需求
```shell
    # 查询表student_bucket中的数据
    hive> select * from student_bucket tablesample(bucket 1 out of 4 on id);
    其中：【3.1.2的抽样规则已改变】
    -tablesample是抽样语句，格式为：TABLESAMPLE(BUCKET x OUT OF y)
    -y必须是table中bucket的倍数或因子。hive基于y决定抽样比例，如table总共分了4份，y=2时，抽取4/2=2个bucket的数据，y=8时，抽取4/8=1/2个bucket的数据
    -x表示从哪个bucket开始抽取，若需要抽取多个分区，以后的分区号为当前分区号加上y。
    注意：x必须小于等于y
```

## 7. 其他常用的查询函数
### 7.1 空字段赋值: NVL
- a. NVL用于给NULL的数据赋值，格式为NVL(string1, replace_with)。功能时如果string1为NULL，则NVL函数返回replace_with的值，否则返回string1的值，
- b. 如果二者均为NULL，则返回NULL
```shell
    hive> select deptno, nvl(comm, -1) from emp; # 如果员工的comm为NULL，则用-1代替
    hive> select deptno, nvl(comm, ename) from emp; # 如果员工的comm为NULL，则用名字代替
```

### 7.2 case when then else end
```shell
    # 求各部门中男女的个数
    hive> select * from emp_sex;
    emp_sex.name	emp_sex.dept_id	emp_sex.sex
    悟空	A	男
    大海	A	男
    宋宋	B	男
    凤姐	A	女
    婷姐	B	女
    婷婷	B	女
    hive> select dept_id,
        > sum(case sex when '男' then 1 else 0 end ) male_count,
        > sum(case sex when '女' then 1 else 0 end) female_count from emp_sex group by dept_id;
```

### 7.3 行转列
- a. CONCAT(string A/col, string B/col ...): 返回输入字符串连接后的结果，支持任一个输入字符串。
- b. CONCAT_WS(separator, str1, str2,...): 特殊形式的CONCAT(),第一个参数为剩余参数间的分隔符。若分隔符为NULL，则返回值也为NULL，该函数会跳过分隔符参数后的任何NULL和字符串。分隔符将被加到被连接的字符串之间。
- C. COLLECT_SET(col): 函数只接受基本数据类型，主要作用是将某字段的值进行去重汇总，生成ARRAY类型的字段
```shell
    # 创建数据库
    hive> create table if not exists person_info(name string, constellation string, blood_type string)
        > row format delimited fields terminated by '\t';
    hive> load data local inpath '/home/test/module/hive/data/person_info.txt' into table person_info;
    hive> select t1.c_b, concat_ws('|', collect_set(t1.name)) from
        > (select concat_ws(',',  constellation, blood_type) c_b, name from person_info) t1
        > group by t1.c_b;
```

### 7.4 列转行
- a. EXPLODE(col): 将hive一列中复杂的array或map结构拆分成多行
- b. LATERAL VIEW udtf(expression) table Alias as columnAlias: 用于和split, explode等UDTF一起使用，它能够将一列数据拆分成多行数据，在此基础上可以对拆分后的数据进行聚合
```shell
    示例：
    hive> select * from movie;
    movie.name	movie.category
    《疑犯追踪》	["悬疑","动作","科幻","剧情"]
    《Lie To Me》	["悬疑","警匪","动作","心理","剧情"]
    《战狼2》	["战争","动作","灾难"]
    hive> select name, categories from movie
        > lateral view explode(category) t as categories;
```

### 7.5 窗口函数
- a. OVER(): 指定分析函数工作的数据窗口大小，这个数据窗口大小可能会随着行的变化而变化。一般紧跟聚合函数
- b. 限定窗口大小：
- CURRENT ROW: 当前行
- n PRECEDING: 往前n行数据  
- n FOLLOWING: 往后n行数据
- UNBOUNDED: 起点    
- UNBOUNDED PRECEDING: 表示从前面的起点   
- UNBOUNDED FOLLOWING: 表示到后面的终点
- LAG(col, n): 往前第n行数据     
- LEAD(col, n): 往后第n行数据
- NTILE(n): 把有序分区中的行分发到指定数据的组中，各个组有编号，编号从1开始，对于每一行，NTILE返回此行所属的组
```shell
    hive> select * from business;
    business.name	business.orderdata	business.cost
    jack	2017-01-01	10
    tony	2017-01-02	15
    jack	2017-02-03	23
    tony	2017-01-04	29
    jack	2017-01-05	46
    jack	2017-04-06	42
    tony	2017-01-07	50
    jack	2017-01-08	55
    mart	2017-04-08	62
    mart	2017-04-09	68
    neil	2017-05-10	12
    mart	2017-04-11	75
    neil	2017-06-12	80
    mart	2017-04-13	94
    # 查询在2017年4月份购买过的顾客及总人数
    hive> select name,count(*) from business where substring(orderdate,1,7)='2017-04' group by name; # 以行为基准，对分组后每组进行count(*)的个数
    name	_c1
    jack	1
    mart	4
    hive> select name,count(*) over() from business where substring(orderdate,1,7)='2017-04' group by name; # 以组为基准，统计分组的个数
    name	count_window_0
    mart	2
    jack	2
    # 查询顾客的购买明细及月购买总额
    hive> select *, sum(cost) over(distribute by month(orderdate)) from business;
    hive> select *, sum(cost) over(partition by month(orderdate)) from business;
    # 要将cost按照日期进行累加
    hive> select *, sum(cost) over(sort by orderdate rows between unbounded preceding and current row) from business; # 窗口中先按照orderdate排序，然后每一组中的sum由第一行到当前行的累加而成
    # 要将cost按照日期每三行进行累加
    hive> select *, sum(cost) over(sort by orderdate rows between 1 preceding and 1 following) from business;
    # 要将cost按照日期且按照名称分区进行累加
    hive> select *, sum(cost) over(distribute by name sort by orderdate rows between unbounded preceding and current row) from business;
    hive> select *, sum(cost) over(sort by orderdate rows between  current row and unbounded following) from business;
    # 查询顾客上次的购买时间
    hive> select *, lag(orderdate, 1) over(distribute by name sort by orderdate) from business;
    # 查询顾客上次以及下次的购买时间
    hive> select *,
        > lag(orderdate, 1) over(distribute by name sort by orderdate),
        > lead(orderdate, 1) over(distribute by name sort by orderdate) from business;
    # 查询前20%时间的订单信息
    hive> select * from (select *, ntile(5) over(sort by orderdate) gid from business) t1 where t1.gid=1;
```

### 7.6 rank
- a. rank(): 排序相同时会重复，总数不改变
- b. dense_rank(): 排序相同时会重复，总数会减小
- c. row_number(): 会根据顺序计算
- d. 如上三个函数后面必须跟窗口函数over
```shell
    示例数据：
    score.name	score.subject	score.score
    孙悟空	语文	87
    孙悟空	数学	95
    孙悟空	英语	68
    大海	语文	94
    大海	数学	56
    大海	英语	84
    宋宋	语文	64
    宋宋	数学	86
    宋宋	英语	84
    婷婷	语文	65
    婷婷	数学	85
    婷婷	英语	78
    hive> select *, row_number() over() from score;
    score.name	score.subject	score.score	row_number_window_0
    婷婷	英语	78	1
    婷婷	数学	85	2
    婷婷	语文	65	3
    宋宋	英语	84	4
    宋宋	数学	86	5
    宋宋	语文	64	6
    大海	英语	84	7
    大海	数学	56	8
    大海	语文	94	9
    孙悟空	英语	68	10
    孙悟空	数学	95	11
    孙悟空	语文	87	12
    # 按需求查询响应的数据
    hive> select *,
        > rank() over(partition by subject order by score desc),
        > dense_rank() over(partition by subject order by score desc),
        > row_number() over(partition by subject order by score desc)
        > from score;
    score.name	score.subject	score.score	rank_window_0	dense_rank_window_1	row_number_window_2
    孙悟空	数学	95	1	1	1
    宋宋	数学	86	2	2	2
    婷婷	数学	85	3	3	3
    大海	数学	56	4	4	4
    宋宋	英语	84	1	1	1
    大海	英语	84	1	1	2
    婷婷	英语	78	3	2	3
    孙悟空	英语	68	4	3	4
    大海	语文	94	1	1	1
    孙悟空	语文	87	2	2	2
    婷婷	语文	65	3	3	3
    宋宋	语文	64	4	4	4
```